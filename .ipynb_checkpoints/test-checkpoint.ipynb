{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\anaconda3\\envs\\bigdl-prompt-engineer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-22 10:42:16,595 - WARNING - BigdlNativeLLM has been deprecated, please switch to the new LLM API for sepcific models.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "from bigdl.llm.langchain.llms import TransformersLLM\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "MODEL_NAME = \"chatglm2-6b\"\n",
    "\n",
    "def load_transformers_llm():\n",
    "    return TransformersLLM.from_model_id_low_bit(\n",
    "        model_id=\"F:/Study/Code/llm-models/chatglm2-6b\",\n",
    "        model_kwargs={\"temperature\": 0.9, \"trust_remote_code\": True},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = load_transformers_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a chatbot having a conversation with a human.\"), # The persistent system prompt\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"), # Where the memory will be stored.\n",
    "    HumanMessagePromptTemplate.from_template(\"我的问题是：```{human_input}```。如果我的问题不满足语法，请完善这句话，并返回完善过的问题\"), # Where the human input will injected\n",
    "])\n",
    "    \n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    llm_kwargs={\"max_new_tokens\": 500}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human.\n",
      "Human: 我的问题是：```复旦大学 地点？```。如果我的问题不满足语法，请完善这句话，并返回完善过的问题\u001b[0m\n",
      "。\n",
      "\n",
      "Chatbot: 非常抱歉，我不太明白您的问题。您能否提供更多上下文或信息，以便我更好地回答您的问题？\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'System: You are a chatbot having a conversation with a human.\\nHuman: 我的问题是：```复旦大学 地点？```。如果我的问题不满足语法，请完善这句话，并返回完善过的问题。\\n\\nChatbot: 非常抱歉，我不太明白您的问题。您能否提供更多上下文或信息，以便我更好地回答您的问题？'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"复旦大学 地点？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
